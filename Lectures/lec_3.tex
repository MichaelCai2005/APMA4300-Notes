\lecture{4}{Feb 6 10:10}{}
\begin{remark}
    We can start with the form 
    \[
        x = Px +y 
    \]
    where we wish to solve for \(x\). We can construct an iterative way of calculating 
    where \(x\) is a vector. THe iteration is based on the equation 
    \[
        \left( I + (A-I) \right) x = y
    \]
    \[
        \to x = (I-A)x +y
    \]
    We can calculate iteratively for the \(k+1\) term where 
    \[
        x^{k+1} = Px^k +y, \text{given } x^0
    \]
    \[
        \begin{pmatrix}
             x_1 \\
             x_2  \\
        \end{pmatrix} ^{k+1}
        = 
        \begin{pmatrix}
            \frac{1}{2} &   \\
             &   \frac{1}{2}\\
        \end{pmatrix}
        \begin{pmatrix}
             x_1 \\
             x_2 \\
        \end{pmatrix}^k + 
        \begin{pmatrix}
              1 \\
              3 \\
        \end{pmatrix}, \text{given } \begin{pmatrix}
              x_1 \\
              x_2\\
        \end{pmatrix}^0 = \begin{pmatrix}
              5 \\
              6\\
        \end{pmatrix}
    \]
    We can thus solve to get the next term in the results. If \(x^k\) converges to some vector 
    we can write this as 
    \[
        \overline{x}  = P \overline{x} + y 
    \]
    This tells us that if we continue the calculations, we find the solution to the equation. Thus 
    we wish to find the stable solutions. The trivial case is for when \(P = 0 \). Another case 
    is where 
    \[
        P x^k \to 0 
    \]
    which gives a stable solution. Thus, we see that all values of \(P < 1\) lead to 
    convergence. Thus when the "size" is less than 1, we will have a convergence. We can do this 
    to find a solution to the form 
    \[
        x = Px +y
    \]
    Thus we only need that the size of \(P \) which is \(\rho (P) < 1\) and a guess 
    \(x^0\) . 
\end{remark}
\begin{remark}
    Iterative Schemes:
    They are used in the solution of linear and nonlinear problems with the form above. For such schemes 
    we need the following 
    \begin{enumerate}
        \item Starting point
        \item Convergence 
        \item Rate of Convergence
        \item Stopping Criteria: We stop when \(\Delta x < \epsilon \) 
    \end{enumerate}
    Note that in the limiting case we will have the following equations 
    \[
        x^{k+1}  = B x^k +y
    \]
    \[
        x = Bx +y
    \]
    we will measure how far we are from the solution and we can denote \(\epsilon \)  as the error. 
    \[
        \epsilon^{k+1} = B \epsilon^k
    \]
    If \(\lVert B \rVert < 1 \) then we get a geometric series decreasing where 
    \[
        \lim_{k \to \infty} \epsilon^k \to 0, \text{and } x^k \to  x
    \]
\end{remark}
\begin{remark}
    Schemes for Linear Systems: 

    To solve for \(Ax=y\) we can rewrite this as \(x = (I-A) x +y\) where \(B = I-A\). 
    However this is not a good way to construct a \(B\) that works. There is a less naive strategy where we can 
    construct a \(B\)  that works. We can split up \(A\) 
    \( A= P-N\) 
    \[
        (P-N)x = y
    \]
    \[
        x = P^{-1}Nx + P^{-1}y
    \]
    where we must have that 
    \[
        \rho (B) = \rho (P^{-1}N) < 1
    \]
    This can be rewritten as 
    \[
        x = Bx + \widetilde{y} 
    \]
    By choosing \(P\) to be invertible, we can rewrite the iteration to be the form we had. 
\end{remark}

\begin{definition}
    Jacobi Iteration:
    \begin{enumerate}
        \item \(D_A\): the diagonal matrix of \(A\) 
        \item \(L_A\): the negative of \(A\) lower triangular
        \item \(U_A\): the negative of \(A\) upper triangular
    \end{enumerate}
\end{definition}

\begin{definition}
    Richardson Iteration: 
    \[
        P = I, \text{therefore } N= I-A
    \]
\end{definition}